{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-massive-world/organ-segmentation/blob/main/thesis_stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dSuv9E4p10F"
      },
      "outputs": [],
      "source": [
        "#####CTRL+F and search for 'CTRL+START', to go to the starting cell block.\n",
        "\n",
        "\n",
        "from IPython.display import clear_output as clear,Image\n",
        "import json,os,time,tarfile,shutil,numpy as np, nibabel\n",
        "from glob import glob\n",
        "\n",
        "from nibabel import load,Nifti1Image,save\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "##############JUST PLOTTING\n",
        "\n",
        "try:\n",
        "  from humanfriendly import format_timespan, format_size\n",
        "except ModuleNotFoundError:\n",
        "  !pip install humanfriendly\n",
        "  from humanfriendly import format_timespan, format_size\n",
        "\n",
        "\n",
        "try:\n",
        "  import pydicom\n",
        "except ModuleNotFoundError:\n",
        "  !pip install pydicom\n",
        "  import pydicom\n",
        "\n",
        "\n",
        "try:\n",
        "  import dicom2nifti\n",
        "except ModuleNotFoundError:\n",
        "  !pip install dicom2nifti\n",
        "  import dicom2nifti\n",
        "  \n",
        "\n",
        "try:\n",
        "  import SimpleITK as sitk\n",
        "except ModuleNotFoundError:\n",
        "  !pip install simpleitk\n",
        "  import SimpleITK as sitk\n",
        "\n",
        "\n",
        "try:\n",
        "  import wget\n",
        "except ModuleNotFoundError:\n",
        "  !pip install wget\n",
        "  import wget\n",
        "\n",
        "try:\n",
        "  import monai\n",
        "  from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "  )\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "  !pip install monai\n",
        "  !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        ")\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "\n",
        "\n",
        "\n",
        "clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb2gRBX4XJNP"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGUZhgkCpxYp"
      },
      "outputs": [],
      "source": [
        "def to_json(dic, name, string):\n",
        "  # print('to_json:',string,sep,name)c\n",
        "  path = main_path\n",
        "  a = 1\n",
        "  if string == 'write':\n",
        "    \n",
        "    if dic == {}:\n",
        "      print('Given Dictionary is empty. Check again!!')\n",
        "      return False\n",
        "    if a == 1:  \n",
        "\n",
        "      with open(path+name+'.json','w') as fp:\n",
        "        json.dump(dic,fp)\n",
        "    else:\n",
        "      print('Did not save anything.')\n",
        "      return False\n",
        "    \n",
        "    # print('saved '+name+'.json')\n",
        "    print('saved',sep,name,'('+getfilesize(path+name+'.json',1)+')')\n",
        "\n",
        "  if string == 'read':\n",
        "    with open(path+name+'.json','r') as fp:\n",
        "      data = json.load(fp)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def getfilesize(the_file,the_type):\n",
        "  file_size = os.path.getsize(the_file)\n",
        "  actual_file_size = format_size(file_size)\n",
        "\n",
        "  la_output = the_file.split('/')[-1]+sep+actual_file_size\n",
        "  \n",
        "  if the_type not in empty_list:\n",
        "    if the_type == 1:\n",
        "      return la_output.split(sep)[-1]\n",
        "    else:\n",
        "      return file_size\n",
        "  else:\n",
        "    print(la_output)\n",
        "\n",
        "def get_dir_size(path='.'):\n",
        "    total = 0\n",
        "    with os.scandir(path) as it:\n",
        "        for entry in it:\n",
        "            if entry.is_file():\n",
        "                total += entry.stat().st_size\n",
        "            elif entry.is_dir():\n",
        "                total += get_dir_size(entry.path)\n",
        "    \n",
        "    return total\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2nOBpPuyPT5"
      },
      "outputs": [],
      "source": [
        "separator = ' —— '\n",
        "sep = ' — '\n",
        "empty_list = ['',\"\",\" \",' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGM5B_uKthlT"
      },
      "outputs": [],
      "source": [
        "main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "livpath = main_path+'Liver/Task03_Liver/'\n",
        "mypath = main_path+'test_path/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9CZnY3gtI1a"
      },
      "outputs": [],
      "source": [
        "# database = to_json({},'Liver/Task03_Liver/dataset','read')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NW9i3AByuK7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def listdir_nohidden(path):\n",
        "  for f in os.listdir(path):\n",
        "    if not f.startswith('.'):\n",
        "      yield f\n",
        "\n",
        "def convertNsave(arr,file_dir, index=0):\n",
        "    \n",
        "  dicom_file = pydicom.dcmread(main_path+'sample_dicom/dcmimage.dcm')\n",
        "  arr = arr.astype('uint16')\n",
        "  dicom_file.Rows = arr.shape[0]\n",
        "  dicom_file.Columns = arr.shape[1]\n",
        "  dicom_file.PhotometricInterpretation = \"MONOCHROME2\"\n",
        "  dicom_file.SamplesPerPixel = 1\n",
        "  dicom_file.BitsStored = 16\n",
        "  dicom_file.BitsAllocated = 16\n",
        "  dicom_file.HighBit = 15\n",
        "  dicom_file.PixelRepresentation = 1\n",
        "  dicom_file.PixelData = arr.tobytes()\n",
        "  dicom_file.save_as(os.path.join(file_dir, f'slice{index}.dcm'))\n",
        "\n",
        "def nifti2dicom_1file(nifti_dir, out_dir):\n",
        "\n",
        "\n",
        "  nifti_file = nibabel.load(nifti_dir)\n",
        "  nifti_array = nifti_file.get_fdata()\n",
        "  number_slices = nifti_array.shape[2]\n",
        "  print('INPUT: ',nifti_dir)\n",
        "  print('outPUT: ',out_dir)\n",
        "\n",
        "  for slice_ in tqdm(range(number_slices)):\n",
        "    convertNsave(nifti_array[:,:,slice_], out_dir, slice_)\n",
        "\n",
        "def nifti2dicom_mfiles(file,out_dir=''):\n",
        "\n",
        "  # files = listdir_nohidden(nifti_dir)\n",
        "  # c = 0\n",
        "  # for file in files:\n",
        "    # clear()\n",
        "  # print(str(c+1))\n",
        "  \n",
        "  print('Extracting',sep,file+'\\n')\n",
        "  # in_path = os.path.join(nifti_dir, file.split('/')[-1])\n",
        "  out_path = os.path.join(out_dir, file.split('/')[-1])\n",
        "  # if os.path.exists(out_path) is not True:\n",
        "  #   os.mkdir(out_path)\n",
        "  nifti2dicom_1file(file, out_path)\n",
        "    \n",
        "    # c+=1\n",
        "\n",
        "      \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEfpAU7DBs63"
      },
      "outputs": [],
      "source": [
        "def slices_to_folder(patient,group_val,cluster,g64,dcom_folder):\n",
        "# patient = the_name_of_the_patient\n",
        "# group_val = group_no\n",
        "  list_of_files = cluster\n",
        "  copy_path = dcom_folder+patient+'.nii.gz/'\n",
        "  paste_path = g64+patient+'_'+str(group_val)\n",
        "  print('\\ncopying from',copy_path)\n",
        "  print('saving',paste_path)\n",
        "  if os.path.exists(paste_path) is not True:\n",
        "    os.mkdir(paste_path)\n",
        "  for i in list_of_files:\n",
        "    shutil.copy(copy_path+i,paste_path+'/'+i)\n",
        "  \n",
        "\n",
        "def sequential_series(multiplier,path):\n",
        "  h = []\n",
        "  \n",
        "  \n",
        "  for i in range(multiplier*64, (multiplier+1)*64):\n",
        "    h.append(path+'/slice'+str(i)+'.dcm')\n",
        "  #   k.append('slice'+str(i)+'.dcm')\n",
        "  # print(k)\n",
        "  ranger = h[0].split('/')[-1]+' to '+h[-1].split('/')[-1]\n",
        "  print('slice range',ranger,'\\nsize:',len(h))\n",
        "  return tuple(h)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CAIirs9hNwL"
      },
      "outputs": [],
      "source": [
        "def prepare(in_dir, kfold_train, kfold_test, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128,128,64], cache=False):\n",
        "\n",
        "    \"\"\"\n",
        "    This function is for preprocessing, it contains only the basic transforms, but you can add more operations that you \n",
        "    find in the Monai documentation.\n",
        "    https://monai.io/docs.html\n",
        "    \"\"\"\n",
        "\n",
        "    set_determinism(seed=0)\n",
        "\n",
        "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
        "    path_train_volumes = [path_train_volumes[x] for x in kfold_train]\n",
        "\n",
        "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
        "    path_train_segmentation = [path_train_segmentation[x] for x in kfold_train]\n",
        "\n",
        "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
        "    path_test_volumes = [path_test_volumes[x] for x in kfold_test]\n",
        "\n",
        "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
        "    path_test_segmentation = [path_test_segmentation[x] for x in kfold_test]\n",
        "\n",
        "    \n",
        "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
        "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "\n",
        "    train_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True), \n",
        "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max,b_min=0.0, b_max=1.0, clip=True), \n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "            \n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if cache:\n",
        "        train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n",
        "        train_loader = DataLoader(train_ds, batch_size=1)\n",
        "\n",
        "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    else:\n",
        "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "        train_loader = DataLoader(train_ds, batch_size=1)\n",
        "\n",
        "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "        return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woQrplJ_vTQF"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from monai.losses import DiceLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "def dice_metric(predicted, target):\n",
        "    '''\n",
        "    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it \n",
        "    to calculate a metric value for the training and the validation.\n",
        "    '''\n",
        "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "    value = 1 - dice_value(predicted, target).item()\n",
        "    return value\n",
        "\n",
        "def calculate_weights(val1, val2):\n",
        "    '''\n",
        "    In this function we take the number of the background and the forgroud pixels to return the `weights` \n",
        "    for the cross entropy loss values.\n",
        "    '''\n",
        "    count = np.array([val1, val2])\n",
        "    summ = count.sum()\n",
        "    weights = count/summ\n",
        "    weights = 1/weights\n",
        "    summ = weights.sum()\n",
        "    weights = weights/summ\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    try:\n",
        "      save_loss_train = list(np.load(os.path.join(model_dir, 'loss_train.npy')))\n",
        "      save_loss_test = list(np.load(os.path.join(model_dir, 'loss_test.npy')))\n",
        "      save_metric_train = list(np.load(os.path.join(model_dir, 'metric_train.npy')))\n",
        "      save_metric_test = list(np.load(os.path.join(model_dir, 'metric_test.npy')))\n",
        "    except FileNotFoundError:\n",
        "      save_loss_train = []\n",
        "      save_loss_test = []\n",
        "      save_metric_train = []\n",
        "      save_metric_test = []\n",
        "    train_loader, test_loader = data_in\n",
        "    \n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # clear()\n",
        "        # try:\n",
        "        #   plt= 0\n",
        "        #   epoch_checker()\n",
        "        # except FileNotFoundError:\n",
        "        #   print('Not doing the EPOCH CHECKER')\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "        \n",
        "        model.train()\n",
        "        try:\n",
        "          train_epoch_loss = save_loss_train[-1]\n",
        "          epoch_metric_train = save_metric_train[-1]\n",
        "        except IndexError:\n",
        "          train_epoch_loss = 0\n",
        "          epoch_metric_train = 0\n",
        "          \n",
        "        train_step = 0\n",
        "        \n",
        "        for batch_data in train_loader:\n",
        "            clear()\n",
        "            train_step += 1\n",
        "\n",
        "            volume = batch_data[\"vol\"]\n",
        "            label = batch_data[\"seg\"]\n",
        "            label = label != 0\n",
        "            volume, label = (volume.to(device), label.to(device))\n",
        "\n",
        "            optim.zero_grad()\n",
        "            outputs = model(volume)\n",
        "            \n",
        "            train_loss = loss(outputs, label)\n",
        "            \n",
        "            train_loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            print(\n",
        "                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
        "                f\"Train_loss: {train_loss.item():.4f}\")\n",
        "\n",
        "            train_metric = dice_metric(outputs, label)\n",
        "            epoch_metric_train += train_metric\n",
        "            print(f'Train_dice: {train_metric:.4f}')\n",
        "            !nvidia-smi\n",
        "            # time.sleep(1)\n",
        "            # clear()\n",
        "\n",
        "        clear()\n",
        "        print('-'*20)\n",
        "        \n",
        "        train_epoch_loss /= train_step\n",
        "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
        "        save_loss_train.append(train_epoch_loss)\n",
        "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
        "        \n",
        "        epoch_metric_train /= train_step\n",
        "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
        "\n",
        "        save_metric_train.append(epoch_metric_train)\n",
        "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
        "        \n",
        "        \n",
        "        if (epoch + 1) % test_interval == 0:\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                try:\n",
        "                  test_epoch_loss = save_loss_test[-1]\n",
        "                  epoch_metric_test = save_metric_test[-1]\n",
        "                except IndexError:\n",
        "                  test_epoch_loss = 0\n",
        "                  epoch_metric_test = 0\n",
        "\n",
        "                test_metric = 0\n",
        "                \n",
        "                test_step = 0\n",
        "\n",
        "                for test_data in test_loader:\n",
        "                    # clear()\n",
        "                    test_step += 1\n",
        "\n",
        "                    test_volume = test_data[\"vol\"]\n",
        "                    test_label = test_data[\"seg\"]\n",
        "                    test_label = test_label != 0\n",
        "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
        "                    \n",
        "                    test_outputs = model(test_volume)\n",
        "                    \n",
        "                    test_loss = loss(outputs, test_label)\n",
        "                    test_epoch_loss += test_loss.item()\n",
        "                    test_metric = dice_metric(test_outputs, test_label)\n",
        "                    epoch_metric_test += test_metric\n",
        "\n",
        "\n",
        "                    \n",
        "                \n",
        "                test_epoch_loss /= test_step\n",
        "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
        "                \n",
        "                # clear()\n",
        "                save_loss_test.append(test_epoch_loss)\n",
        "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
        "\n",
        "                epoch_metric_test /= test_step\n",
        "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
        "                save_metric_test.append(epoch_metric_test)\n",
        "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
        "                clear()\n",
        "                print('checking epoch...')\n",
        "                time.sleep(1)\n",
        "                epoch_checker()\n",
        "                clear()\n",
        "                \n",
        "                \n",
        "                if epoch_metric_test > best_metric:\n",
        "                    best_metric = epoch_metric_test\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), os.path.join(\n",
        "                        model_dir, \"best_metric_model.pth\"))\n",
        "                \n",
        "                print(\n",
        "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
        "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                    f\"at epoch: {best_metric_epoch}\"\n",
        "                  )\n",
        "        \n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "        f\"at epoch: {best_metric_epoch}\")\n",
        "    \n",
        "  \n",
        "\n",
        "def calculate_pixels(data):\n",
        "    val = np.zeros((1, 2))\n",
        "\n",
        "    for batch in tqdm(data):\n",
        "        batch_label = batch[\"seg\"] != 0\n",
        "        _, count = np.unique(batch_label, return_counts=True)\n",
        "\n",
        "        if len(count) == 1:\n",
        "            count = np.append(count, 0)\n",
        "        val += count\n",
        "\n",
        "    print('The last values:', val)\n",
        "    return val\n",
        "\n",
        "def timenow():\n",
        "  from datetime import date as datetimedate, datetime, timedelta\n",
        "  import pytz\n",
        "  return datetime.now(pytz.timezone(\"Etc/GMT-6\")).strftime('%d %B %Y, %I:%M:%S %p')\n",
        "# timenow()\n",
        "def epoch_checker():\n",
        "  from matplotlib import pyplot as plt\n",
        "  train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
        "  train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
        "  test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
        "  test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))\n",
        "  fig,ax = plt.subplots(figsize=(6,12),nrows=2,ncols=1,)\n",
        "  \n",
        "  a, = ax[0].plot(test_loss,'o-',label='test_loss')\n",
        "  b, = ax[0].plot(train_loss,'x--',label='train_loss')\n",
        "  # ax.grid()\n",
        "  ax[0].set_title('DICE loss')\n",
        "  ax[0].legend(handles=[a,b])\n",
        "  # plt.legend()\n",
        "  ax[0].grid()\n",
        "  # plt.subplot(2,1,2)\n",
        "  \n",
        "  a, = ax[1].plot(test_metric,'o-',label='test_metric')\n",
        "  b, = ax[1].plot(train_metric,'x--',label='train_metric')\n",
        "\n",
        "  ax[1].legend(handles=[a,b])\n",
        "  ax[1].set_title('DICE metric')\n",
        "  plt.suptitle('\\n\\nepoch'+sep+str(len(train_loss))+'\\n'+timenow())\n",
        "  ax[1].grid()\n",
        "  # if os.path.exists(model_dir+'graphs/') is False:\n",
        "  #   os.mkdir(model_dir+'graphs/')\n",
        "  # plt.legend()\n",
        "  \n",
        "  plt.savefig(model_dir+'graphs/'+timenow()+'.png',bbox_inches='tight')\n",
        "  # plt = 0\n",
        "  \n",
        "# epoch_checker()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SFPQf4FyL90"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "# train(model, data_in, loss_function, optimizer, 20, model_dir)\n",
        "# except ZeroDivisionError:\n",
        "#   clear()\n",
        "#   train(model, data_in, loss_function, optimizer, 600, model_dir)\n",
        "def timenow():\n",
        "  from datetime import date as datetimedate, datetime, timedelta\n",
        "  import pytz\n",
        "  return datetime.now(pytz.timezone(\"Etc/GMT-6\")).strftime('%d %B %Y, %I:%M:%S %p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMbihfDYmfjK"
      },
      "outputs": [],
      "source": [
        "##############JUST PLOTTING\n",
        "import numpy as np, nibabel\n",
        "from matplotlib import pyplot as plt\n",
        "from monai.transforms import(\n",
        "  Compose,\n",
        "  AddChanneld,\n",
        "  LoadImaged,\n",
        "  Resized,\n",
        "  ToTensord,\n",
        "  Spacingd,\n",
        "  Orientationd,\n",
        "  ScaleIntensityRanged,\n",
        "  CropForegroundd,\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "from monai.utils import first\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    Activations,\n",
        ")\n",
        "\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.data import CacheDataset, DataLoader, Dataset\n",
        "from monai.inferers import sliding_window_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RjBCvosH2jx"
      },
      "outputs": [],
      "source": [
        "\n",
        "trpath = main_path+'imagesTr_path'\n",
        "labels = main_path+'labels_path'\n",
        "tspath = main_path+'imagesTs_path'\n",
        "traindir = main_path+'TRAINER/'\n",
        "tsseg = traindir+'TestSegmentation/'\n",
        "tsvol = traindir+'TestVolumes/'\n",
        "trseg = traindir+'TrainSegmentation/'\n",
        "trvol = traindir+'TrainVolumes/'\n",
        "data_dir = traindir\n",
        "model_dir = main_path+'MODELscratch/'\n",
        "kfold = main_path+'KFold/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMHZYPt26UG8"
      },
      "outputs": [],
      "source": [
        "def predicting_liver_mask_for_test_files_without_segmentation(test_files,start_slice,end_slice,colormap='grey',model_path=main_path+'/MODELscratch/best_metric_model.pth'):\n",
        "# colormap = 'gray'\n",
        "  file_name = test_files[0]['vol'].split(tsvol)[-1]\n",
        "  print('Validating against',test_files[0]['vol'].split(trvol)[-1])\n",
        "  print('from slice',start_slice,'to',end_slice)\n",
        "\n",
        "\n",
        "  test_transforms = Compose(\n",
        "      [\n",
        "          LoadImaged(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "          AddChanneld(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "          Spacingd(keys=[\"vol\", \"seg\"],allow_missing_keys=True, pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "          Orientationd(keys=[\"vol\", \"seg\"],allow_missing_keys=True, axcodes=\"RAS\"),\n",
        "          ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "          CropForegroundd(keys=['vol', 'seg'], source_key='vol',allow_missing_keys=True),\n",
        "          Resized(keys=[\"vol\", \"seg\"],allow_missing_keys=True, spatial_size=[128,128,64]),   \n",
        "          ToTensord(keys=[\"vol\", \"seg\"],allow_missing_keys=True),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "\n",
        "  # test_ds = Dataset(data=test_files)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  device = torch.device(my_device)\n",
        "  model = UNet(\n",
        "      dimensions=3,\n",
        "      in_channels=1,\n",
        "      out_channels=2,\n",
        "      channels=(16, 32, 64, 128, 256), \n",
        "      strides=(2, 2, 2, 2),\n",
        "      num_res_units=2,\n",
        "      norm=Norm.BATCH,\n",
        "  ).to(device)\n",
        "  if model_path not in empty_list:\n",
        "    model.load_state_dict(torch.load(\n",
        "        model_path,map_location=torch.device(my_device)))\n",
        "    model.eval()\n",
        "\n",
        "  if model_path in empty_list:\n",
        "    model_path = '**no models were used**'\n",
        "  sw_batch_size = 4\n",
        "  roi_size = (128, 128, 64)\n",
        "  with torch.no_grad():\n",
        "      test_patient = first(test_loader)\n",
        "      t_volume = test_patient['vol']\n",
        "      # t_segmentation = test_patient['seg']\n",
        "      \n",
        "      test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "      # tarp = test_outputs\n",
        "      sigmoid_activation = Activations(sigmoid=True)\n",
        "      test_outputs = sigmoid_activation(test_outputs)\n",
        "      # test_outputs = test_outputs > 0.997\n",
        "      test_outputs = test_outputs > .75\n",
        "      # import cv2          \n",
        "      for i in range(start_slice,end_slice+1):\n",
        "          # plot the slice [:, :, 80]\n",
        "          processed_slice = test_patient[\"vol\"][0, 0, :, :, i].numpy()\n",
        "          # target = test_patient[\"seg\"][0, 0, :, :, i].numpy() > 0\n",
        "          target= np.ones([128,128],dtype='float32')\n",
        "          actual_slice = nibabel.load(tsvol+file_name).get_fdata()[:,:,i]\n",
        "          prediction = np.array(test_outputs.detach().cpu()[0,1,:,:,i],dtype='float32')\n",
        "          difference = np.array(np.logical_xor(processed_slice,prediction),dtype='float32')\n",
        "          # difference = 1-(2*(np.logical_and(target,prediction)/np.logical_or(target,prediction)))\n",
        "\n",
        "          processed_slice = correct_orient(processed_slice)\n",
        "          target = correct_orient(target)\n",
        "          actual_slice = correct_orient(actual_slice)\n",
        "          prediction = correct_orient(prediction)\n",
        "          difference = correct_orient(difference)\n",
        "\n",
        "          try:\n",
        "            accuracy = round((1-(abs(np.count_nonzero(difference))/np.count_nonzero(target)))*100,3)\n",
        "            print('xor accuracy:',accuracy)\n",
        "            # accuracy = round(dice_coef(prediction,target)*100,3)\n",
        "            accuracy = round(np.sum(prediction[target==1]*2.0/(np.sum(prediction)+np.sum(target)))*100,3)\n",
        "            print('dice coeff:',accuracy)\n",
        "            \n",
        "          except ZeroDivisionError:\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) != 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)!=0  and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 100\n",
        "          \n",
        "          \n",
        "          # plt.rc('lines',linewidth=1.6)\n",
        "          \n",
        "          fig, ax = plt.subplots(figsize=(30,12))\n",
        "          plt.rc('font',family='serif',size=35)\n",
        "          COLOR = [0,0,0]\n",
        "          # ax.tick_params(size=14)\n",
        "          # ax.yticks(fontsize=14)\n",
        "          plt.axis('on')\n",
        "          plt.rcParams['axes.labelcolor'] = COLOR\n",
        "          plt.rcParams['xtick.labelsize'] = 26\n",
        "          plt.rcParams['ytick.labelsize'] = 0\n",
        "          plt.rcParams['xtick.color'] = COLOR\n",
        "          plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "          # plt.rcParams['text.color'] = [1,1,1]\n",
        "          plt.subplot(1,5,1)\n",
        "          plt.title(f\"SLICE\\n\")\n",
        "          plt.imshow(actual_slice,cmap=colormap)\n",
        "          plt.xticks([0,actual_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "\n",
        "          plt.subplot(1, 5, 2)\n",
        "          plt.title(f\"PROCESSED\\nSLICE\")\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          \n",
        "          plt.subplot(1, 5, 4)\n",
        "          plt.title(f\"OVERLAY\\n\")\n",
        "          mask = prediction\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.imshow(np.ma.masked_where(mask==0,mask),cmap='jet')\n",
        "          \n",
        "          \n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "          \n",
        "          plt.subplot(1, 5, 3)\n",
        "          plt.title(f\"PREDICTION\\n\")\n",
        "          plt.imshow(prediction,cmap=colormap)\n",
        "          plt.xticks([0,prediction.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "          \n",
        "          # clear()\n",
        "          plt.subplot(1,5,5)\n",
        "          plt.title(f\"SEGMENTED\\nPART\")\n",
        "          plt.imshow(processed_slice, cmap='gray', alpha=1.0*(prediction>0))\n",
        "          plt.xticks([0,processed_slice.shape[0]])\n",
        "          plt.yticks([0,0])\n",
        "          # plt.suptitle('TEST FILE: '+tsvol+file_name+'\\nSLICE NUMBER: '+str(i)+'\\n'+\n",
        "          #             'MODEL USED: '+model_path.split(main_path)[-1]+'\\n'+\n",
        "          #             'DEVICE: '+my_device.upper()+'\\n'+\n",
        "          #             # 'THRESHOLD: '+str(threshold_of_error)+' [0 --> 1]\\n'+\n",
        "          #             # 'ACCURACY: '+str(accuracy)+'%\\n'+\n",
        "          #             'TIMESTAMP: '+timenow(),ha='left',va='top',x=0.11,y=.89)\n",
        "          if accuracy > 10 and accuracy < 100:\n",
        "            # clear()\n",
        "            file_name = model_path.split(main_path)[-1].split('/')[2]+' [segmenting]'\n",
        "            print(file_name)\n",
        "            plt.savefig(main_path+'TESTED_DATA/'+file_name+sep+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "            plt.show()\n",
        "            print('SAVED VALIDATION....')\n",
        "          \n",
        "          # plt.savefig(main_path+'TESTED_DATA/TESTVOLUME '+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "          # plt.show()\n",
        "          # print('SAVED VALIDATION....')         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvipDnXNlvoG"
      },
      "outputs": [],
      "source": [
        "def predicting_liver_mask_for_new_files(file_index,start_slice,end_slice,colormap='gray',threshold_of_error=0.53,model_path=main_path+'/MODELscratch/best_metric_model.pth'):\n",
        "\n",
        "  \n",
        "  my_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print('CHOOSING',my_device,'to do the validation')\n",
        "\n",
        "  in_dir = traindir\n",
        "  \n",
        "  path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[0:index]\n",
        "  path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[0:index]\n",
        "\n",
        "  path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "  path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "\n",
        "  train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
        "  test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "  # test_files = test_files\n",
        "  # print(test_files)\n",
        "  # test_files = [{'vol':tsvol+'liver_132_0.nii.gz','seg':trseg+'liver_0_0.nii.gz'}]\n",
        "\n",
        "  test_files = test_files[file_index-1:file_index]\n",
        "  file_name = test_files[0]['vol'].split(trvol)[-1]\n",
        "  print('Validating against',test_files[0]['vol'].split(trvol)[-1])\n",
        "  print('from slice',start_slice,'to',end_slice)\n",
        "\n",
        "\n",
        "  test_transforms = Compose(\n",
        "      [\n",
        "          LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "          AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "          Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "          Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "          ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "          CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "          Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "          ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "\n",
        "  # test_ds = Dataset(data=test_files)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  device = torch.device(my_device)\n",
        "  model = UNet(\n",
        "      dimensions=3,\n",
        "      in_channels=1,\n",
        "      out_channels=2,\n",
        "      channels=(16, 32, 64, 128, 256), \n",
        "      strides=(2, 2, 2, 2),\n",
        "      num_res_units=2,\n",
        "      norm=Norm.BATCH,\n",
        "  ).to(device)\n",
        "  if model_path not in empty_list:\n",
        "    model.load_state_dict(torch.load(\n",
        "        model_path,map_location=torch.device(my_device)))\n",
        "    model.eval()\n",
        "\n",
        "  if model_path in empty_list:\n",
        "    model_path = '**no models were used**'\n",
        "  sw_batch_size = 4\n",
        "  roi_size = (128, 128, 64)\n",
        "  with torch.no_grad():\n",
        "      test_patient = first(test_loader)\n",
        "      t_volume = test_patient['vol']\n",
        "      t_segmentation = test_patient['seg']\n",
        "      \n",
        "      test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "      # tarp = test_outputs\n",
        "      sigmoid_activation = Activations(sigmoid=True)\n",
        "      test_outputs = sigmoid_activation(test_outputs)\n",
        "      # test_outputs = test_outputs > 0.997\n",
        "      test_outputs = test_outputs > .75\n",
        "      # import cv2          \n",
        "      for i in range(start_slice,end_slice+1):\n",
        "          # plot the slice [:, :, 80]\n",
        "          processed_slice = test_patient[\"vol\"][0, 0, :, :, i].numpy()\n",
        "          target = test_patient[\"seg\"][0, 0, :, :, i].numpy() > 0\n",
        "          actual_slice = nibabel.load(trvol+file_name).get_fdata()[:,:,i]\n",
        "          prediction = np.array(test_outputs.detach().cpu()[0,1,:,:,i],dtype='float32')\n",
        "          difference = np.array(np.logical_xor(prediction,target),dtype='float32')\n",
        "          # difference = 1-(2*(np.logical_and(target,prediction)/np.logical_or(target,prediction)))\n",
        "\n",
        "          \n",
        "          processed_slice = correct_orient(processed_slice)\n",
        "          target = correct_orient(target)\n",
        "          actual_slice = correct_orient(actual_slice)\n",
        "          prediction = correct_orient(prediction)\n",
        "          difference = correct_orient(difference)\n",
        "\n",
        "          try:\n",
        "            accuracy = round((1-(abs(np.count_nonzero(difference))/np.count_nonzero(target)))*100,3)\n",
        "            print('xor accuracy:',accuracy)\n",
        "            # accuracy = round(dice_coef(prediction,target)*100,3)\n",
        "            accuracy = round(np.sum(prediction[target==1]*2.0/(np.sum(prediction)+np.sum(target)))*100,3)\n",
        "            print('dice coeff:',accuracy)\n",
        "            \n",
        "          except ZeroDivisionError:\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) != 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)!=0  and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 0\n",
        "            if np.count_nonzero(target)==0 and np.count_nonzero(prediction) == 0:\n",
        "              accuracy = 100\n",
        "          \n",
        "          \n",
        "          # plt.rc('lines',linewidth=1.6)\n",
        "          \n",
        "          fig, ax = plt.subplots(figsize=(30,12))\n",
        "          plt.rc('font',family='serif',size=35)\n",
        "          COLOR = [0,0,0]\n",
        "          # ax.tick_params(size=14)\n",
        "          # ax.yticks(fontsize=14)\n",
        "          plt.axis('on')\n",
        "          plt.rcParams['axes.labelcolor'] = COLOR\n",
        "          plt.rcParams['xtick.labelsize'] = 26\n",
        "          plt.rcParams['ytick.labelsize'] = 0\n",
        "          plt.rcParams['xtick.color'] = COLOR\n",
        "          plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "          plt.subplot(1,5,1)\n",
        "          plt.title(f\"SLICE\\n\")\n",
        "          plt.imshow(actual_slice,cmap=colormap)\n",
        "          plt.xticks([0, actual_slice.shape[0]])\n",
        "          plt.yticks([0, actual_slice.shape[0]])\n",
        "\n",
        "          plt.subplot(1, 5, 2)\n",
        "          plt.title(f\"PROCESSED\\nSLICE\")\n",
        "          plt.imshow(processed_slice,cmap=colormap)\n",
        "          plt.xticks([0, processed_slice.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          \n",
        "          plt.subplot(1, 5, 3)\n",
        "          plt.title(f\"TARGET\\n\")\n",
        "          plt.imshow(target,cmap=colormap)\n",
        "          plt.xticks([0, target.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          # plt.imshow(nibabel.load(test_files[0]['seg']).get_fdata()[:,:,i])\n",
        "          plt.subplot(1, 5, 4)\n",
        "          plt.title(f\"PREDICTION\\n\")\n",
        "          plt.imshow(prediction,cmap=colormap)\n",
        "          plt.xticks([0, prediction.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          \n",
        "          # clear()\n",
        "          plt.subplot(1,5,5)\n",
        "          plt.title(f\"DIFFERENCE\\n\")\n",
        "          plt.imshow(difference,cmap=colormap)\n",
        "          plt.xticks([0, difference.shape[0]])\n",
        "          plt.yticks([0, 0])\n",
        "          # plt.suptitle('TEST FILE: '+file_name+'\\nSLICE NUMBER: '+str(i)+'\\n'+\n",
        "          #             'MODEL USED: '+model_path.split(main_path)[-1]+'\\n'+\n",
        "          #             'DEVICE: '+my_device.upper()+'\\n'+\n",
        "          #             'THRESHOLD: '+str(threshold_of_error)+' [0 --> 1]\\n'+\n",
        "          #             'ACCURACY: '+str(accuracy)+'%\\n'+\n",
        "          #             'TIMESTAMP: '+timenow(),ha='left',va='top',x=0.11,y=.92)\n",
        "          \n",
        "          \n",
        "          if accuracy > 88 and accuracy < 100:\n",
        "            # clear()\n",
        "            file_name = model_path.split(main_path)[-1].split('/')[2]\n",
        "            print(file_name)\n",
        "            plt.savefig(main_path+'TESTED_DATA/'+file_name+sep+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "            plt.show()\n",
        "            print('SAVED VALIDATION....')\n",
        "\n",
        "  # return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNcVvSZJsXu4"
      },
      "outputs": [],
      "source": [
        "# in_dir = traindir\n",
        "# index = 331\n",
        "# path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[0:index]\n",
        "# path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[0:index]\n",
        "\n",
        "# path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "# path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "# path_test_volumes[0],path_train_volumes[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz--hIdcjPVz"
      },
      "outputs": [],
      "source": [
        "# a_min = 200\n",
        "# a_max = -a_min\n",
        "# size = 200\n",
        "# patient = prepare(traindir,a_max=a_max,a_min=a_min,spatial_size=[size,size,64])\n",
        "# show_patient(patient,63)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_d5rrrthjyz"
      },
      "outputs": [],
      "source": [
        "##############JUST PLOTTING\n",
        "def shows_processed_image_pipeline_for_a_random_image():\n",
        "  import numpy as np, nibabel\n",
        "  from matplotlib import pyplot as plt\n",
        "  from monai.transforms import(\n",
        "      Compose,\n",
        "      AddChanneld,\n",
        "      LoadImaged,\n",
        "      Resized,\n",
        "      ToTensord,\n",
        "      Spacingd,\n",
        "      Orientationd,\n",
        "      ScaleIntensityRanged,\n",
        "      CropForegroundd,\n",
        "  )\n",
        "  from monai.data import DataLoader, Dataset, CacheDataset\n",
        "  from monai.utils import set_determinism\n",
        "  from monai.utils import first\n",
        "  in_dir = traindir\n",
        "  main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "  livpath = main_path+'Liver/Task03_Liver/'\n",
        "  mypath = main_path+'test_path/'\n",
        "  trpath = main_path+'imagesTr_path'\n",
        "  labels = main_path+'labels_path'\n",
        "  tspath = main_path+'imagesTs_path'\n",
        "  folder = 'imagesTr'\n",
        "  sixtyfournifties = main_path+'groups_of_64_nifti/'+folder+'/'\n",
        "\n",
        "\n",
        "\n",
        "  inc = 0\n",
        "  index = np.random.randint(0,366)\n",
        "\n",
        "  slice_number1 = np.random.randint(0,64)\n",
        "  # print(index,file_index,slice_number1)\n",
        "\n",
        "\n",
        "  path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "  path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "  test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "\n",
        "  file_index = np.random.randint(0,len(test_files)-1)\n",
        "  test_files = test_files[file_index-1:file_index]\n",
        "  file_name1 = test_files[0]['vol']\n",
        "\n",
        "\n",
        "  # file_name1\n",
        "\n",
        "  slice_number = int(file_name1.split('.nii.gz')[0].split('_')[-1])*64+slice_number1\n",
        "\n",
        "\n",
        "  # files = os.listdir(sixtyfournifties)\n",
        "  test_image1 = nibabel.load(file_name1).get_fdata()\n",
        "  # test_image2 = nibabel.load(file_name2).get_fdata()\n",
        "  test_image1 = correct_orient(test_image1)\n",
        "  # test_files = [{'vol':file_name1,'seg':file_name1.replace('Volumes','Segmentation')}]\n",
        "\n",
        "  plt = ''\n",
        "  ax = ''\n",
        "  fig = ''\n",
        "  from matplotlib import pyplot as plt\n",
        "      \n",
        "  fig,ax = plt.subplots(figsize=(23,14))\n",
        "  \n",
        "  plt.rc('font',family='serif',size=35)\n",
        "  COLOR = [0,0,0]\n",
        "  # ax.tick_params(size=14)\n",
        "  # ax.yticks(fontsize=14)\n",
        "  # plt.axis('on')\n",
        "  plt.rcParams['axes.labelcolor'] = COLOR\n",
        "  plt.rcParams['xtick.labelsize'] = 26\n",
        "  plt.rcParams['ytick.labelsize'] = 0\n",
        "  plt.rcParams['xtick.color'] = COLOR\n",
        "  plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "\n",
        "  plt.subplot(2,4,1)\n",
        "  \n",
        "  str0 = '1. Loading\\nSlice'\n",
        "  plt.imshow(test_image1[:,:,slice_number1],cmap='gray')\n",
        "  plt.xticks([0, test_image1.shape[0]])\n",
        "  plt.yticks([0, test_image1.shape[0]-1])\n",
        "  plt.title(str0)\n",
        "\n",
        "\n",
        "  str1 = '2. Adding an\\nextra channel'\n",
        "  plt_number = 2\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            # Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            # Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "\n",
        "  str1 = '3. Bilinear\\nSpacing'\n",
        "  plt_number = 3\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            # Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '4. Correcting\\nOrientation'\n",
        "  plt_number = 4\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            # ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '5. Scaling\\nIntensity'\n",
        "  plt_number = 5\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            # CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '6. Croping\\nForeground'\n",
        "  plt_number = 6\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            # Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  a,b = test_image2.shape\n",
        "  \n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  # plt.xticks([0, test_image2.shape[1]])\n",
        "  # plt.yticks([test_image2.shape[0]-1-test_image2.shape[1], test_image2.shape[0]-1])\n",
        "  plt.xticks([0,a])\n",
        "  plt.yticks([test_image2.shape[0]-1-b,test_image2.shape[0]-1])\n",
        "  str1 = '7. Resizing\\n'\n",
        "  plt_number = 7\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  str1 = '8. Processed\\nSlice'\n",
        "  plt_number = 8\n",
        "  test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
        "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "        ]\n",
        "    )\n",
        "  test_ds = Dataset(data=test_files, transform=test_transforms)\n",
        "  test_loader = DataLoader(test_ds, batch_size=1)\n",
        "  test_patient = first(test_loader)\n",
        "  test_image2 = test_patient['vol'][0,0,:,:,slice_number1].numpy()\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  plt.subplot(2,4,plt_number)\n",
        "  plt.imshow(test_image2,cmap='gray')\n",
        "  plt.title(str1)\n",
        "  plt.xticks([0, test_image2.shape[0]])\n",
        "  plt.yticks([0, test_image2.shape[0]-1])\n",
        "\n",
        "  # plt.suptitle('Processing '+file_name1.split(trvol)[-1]+' at slice number '+str(slice_number1))\n",
        "  plt.savefig(main_path+'TESTED_DATA/PREPROCESSING IMAGE '+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "  plt.show()\n",
        "  print('SAVED PREP....')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG-0otxNuiq7"
      },
      "outputs": [],
      "source": [
        "# epoch_checker()\n",
        "clear()\n",
        "my_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('CHOOSING',my_device,'to do the training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgHbmvmlJ9ZX"
      },
      "outputs": [],
      "source": [
        "# ##getting the file sizes of the directories in the thesis_database folder\n",
        "# dontcheck = ['Liver','imagesTr_path','imagesTs_path','labelsTr','groups_of_64','groups_of_64_nifti','groups_of_64_nifti_non_empty']\n",
        "# for files in os.listdir(main_path):\n",
        "#   if files in dontcheck:\n",
        "#     continue\n",
        "#   try:\n",
        "#     print(files,sep,format_size(get_dir_size(main_path+files)))\n",
        "#   except NotADirectoryError:\n",
        "#     getfilesize(main_path+files,'')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pee6m0Y9cvtH"
      },
      "source": [
        "CTRL+START\n",
        "#ORGAN SEGMENTATION (LIVER) OF 3D MEDICAL IMAGES USING PYTORCH & MONAI\n",
        "###GROUP 4, Md. Salim Shahed Shajid [2017338016], MD. Ashraf Hossain Ifty [2017338042]\n",
        "\n",
        "thesis_database folder: https://drive.google.com/drive/folders/1VBjfxsrTDK6jChNYg4QCVIurLydUP0fB\n",
        "\n",
        "Add this folder as a shortcut in the root folder 'My Drive.'\n",
        "\n",
        "#FOLDERS OF INTEREST\n",
        "####TRAINER -- contains the data for training and testing.\n",
        "####TESTED_DATA -- contains the validation of the models.\n",
        "\n",
        "#MODEL folders\n",
        "1. MODEL\n",
        "2. MODELscratch\n",
        "3. MODELscratch_2\n",
        "\n",
        "\n",
        "#Summary\n",
        "\n",
        "Dataset from the Decathlon medical image website [http://medicaldecathlon.com/] was collected. It is the Task03_Liver.tar in the folder. Data were extracted [thesis_database/Liver] and then because of uneven slices for each CT scan file [thesis_database/imagesTr_path], we sliced the standalone files in packets of 64 sliced nifti files [.nii.gz]. The segmented slices [thesis_database/labels_path] were also packeted in a similar fashion. \n",
        "After this, we discarded the nifti files that had no segmentation [the corresponding labels file had no data] and put them in the TRAINER folder. The actual slices were copied to the [thesis_database/TRAINER/TrainVolumes] folder, and the segmentation [labels] were copied to the [thesis_database/TRAINER/TrainSegmentation] folder. \n",
        "\n",
        "Then we took files from the TrainVolumes folder, and processed them further to make the training less time consuming. The processing part was to resize the image from [512,512] pixel to [128,128], the foreground [pixels with significant data] and background [pixels with not enough data] were saturated, the orientation was normalized in a consistent permutation i.e. RAS orientation. Then, the image's voxel width and height, were changed to 1.5 to make the processing faster and we further contrasted the images foreground to make the features more prominent. \n",
        "\n",
        "We split the TrainVolume data into random slices for Training and Testing the models accuracy. After that the data were cached into the gpu memory for faster training time, and now, we have a few trained models at various epochs. \n",
        "\n",
        "In the validation part of this system, the model takes in the processed image and predicts a mask where the liver should be. We compare this prediction with the actual label and determine how accurate the prediction was. The comparism is a simple XOR operation between the two images. So, when both pixel value is 1, the result is 0. This why we find the inaccuracy of the prediction and the target.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3GywLTMqM1u"
      },
      "outputs": [],
      "source": [
        "def correct_orient(a):\n",
        "  a = np.fliplr(a)\n",
        "  a = np.rot90(a,3)\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paE5wgk2yMTf"
      },
      "outputs": [],
      "source": [
        "###BEFORE DOING ANYTHING, CTRL+F8, TO RUN ABOVE CELLS AND THEN RUN THIS CELL \n",
        "###AND MOUNT DRIVE\n",
        "###TO SEE IF EVERYTHING IS IN ORDER\n",
        "###TRAINER FOLDER CANNOT BE 0 BYTES\n",
        "dont_check = ['Liver','imagesTr_path','imagesTs_path',\n",
        "              'labels_path','groups_of_64','groups_of_64_nifti','groups_of_64_nifti_non_empty','model_results']\n",
        "for files in os.listdir(main_path):\n",
        "  if files not in dont_check:\n",
        "    try:\n",
        "      print(files,sep,format_size(get_dir_size(main_path+files)))\n",
        "    except NotADirectoryError:\n",
        "      getfilesize(main_path+files,'')\n",
        "    # print(files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fuse = main_path+'fusemachine kaggle/'\n",
        "kag = main_path+'kaggler/'\n",
        "kag = kag+'image-classification-computer-cv-course/'\n",
        "\n",
        "train_folder = kag+'train.tar/train'\n",
        "test_folder = kag+'test.tar/test'\n",
        "val_folder = kag+'val.tar/val'\n",
        "\n",
        "for item in os.listdir(kag):\n",
        "  # if item in ['test.tar.xz']:\n",
        "  if os.path.isdir(kag+item):\n",
        "    print(item+sep+'[directory]')\n",
        "    continue\n",
        "  print(item)\n",
        "#     shutil.unpack_archive(kag+item,kag+os.path.splitext(item)[0])\n",
        "\n",
        "# # for item in os.listdir(kag):\n",
        "# #   print(item)"
      ],
      "metadata": {
        "id": "og1vWRQFqs3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(kag+'val.csv',header=None,names=['image_file','label'])\n",
        "\n",
        "image_files = {}\n",
        "i= 0\n",
        "for item in df['image_file']:\n",
        "  if df.iloc[i,0] in os.listdir(val_folder):\n",
        "    image_files[i]={'location':val_folder+'/'+df.iloc[i,0],\n",
        "                       'label':df.iloc[i,1]}\n",
        "  # print(df.iloc[i,0])\n",
        "  i+=1\n",
        "\n",
        "# print(image_files)\n",
        "file_name = val_folder+'/'+os.listdir(val_folder)[3]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8fmsZl7838Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AfaarhjzjgRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "\n",
        "index = random.randint(0,len(image_files))\n",
        "data = image_files[index]\n",
        "image = data['location']\n",
        "label = data['label']\n",
        "print(image.split('/')[-1])\n",
        "print('label:',label)\n",
        "Image(image)\n"
      ],
      "metadata": {
        "id": "PQFUZtGyBVb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# # Load the data and labels from your dictionary\n",
        "# data = []\n",
        "# labels = []\n",
        "# i = 0\n",
        "# for index, item in image_files.items():\n",
        "    \n",
        "#     print(index)\n",
        "#     display(image_files[index])\n",
        "#     image = cv2.imread(item['location'])\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB format\n",
        "#     image = cv2.resize(image, (224, 224)) # Resize to a consistent shape\n",
        "#     data.append(image)\n",
        "#     labels.append(item['label'])\n",
        "#     clear()\n",
        "#     i+=1\n",
        "\n",
        "\n",
        "# Convert the data and labels to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=1000, validation_data=(test_data, test_labels))\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "cRtdIVuKlvnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "index = int(input())\n",
        "\n",
        "image_path = image_files[index]['location']\n",
        "label = image_files[index]['label']\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "def crop_black_borders(image):\n",
        "    # Convert the image to grayscale\n",
        "    # image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply binary threshold to create a mask of the black regions\n",
        "    _, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours of the black regions\n",
        "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Get the largest contour\n",
        "    max_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Get the bounding box of the contour\n",
        "    x, y, w, h = cv2.boundingRect(max_contour)\n",
        "\n",
        "    # Crop the image to the bounding box\n",
        "    cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "    # cropped_image = cv2.cvtColor(cropped_image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "def detect_tilted_rectangles(image_path):\n",
        "    # Read the image and convert to grayscale\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding to get a binary image\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    # Find contours of all shapes\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter contours to get only rectangles with at least 4 corners\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
        "        if len(approx) == 4:\n",
        "            rects.append(approx)\n",
        "\n",
        "    # Count the number of dotted rectangles in the original image\n",
        "    num_rects = 0\n",
        "    for rect in rects:\n",
        "        x, y, w, h = cv2.boundingRect(rect)\n",
        "        roi = thresh[y:y+h, x:x+w]\n",
        "        contours, _ = cv2.findContours(roi, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for cnt in contours:\n",
        "            if cv2.contourArea(cnt) < 10:\n",
        "                continue\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            if rect[1][0] > 50 and rect[1][1] > 2:\n",
        "                num_rects += 1\n",
        "    print('before rotating num_rects:',num_rects)\n",
        "    # Rotate the image by 1 degree at a time until we find at least 20 rectangles\n",
        "    angle = 0\n",
        "    while num_rects < 20:\n",
        "        # Rotate the image by 1 degree\n",
        "        print('ANGLE:',angle,'num_rects:',num_rects)\n",
        "        angle += 1\n",
        "        rotated = imutils.rotate_bound(gray, angle)\n",
        "\n",
        "        # Apply adaptive thresholding to get a binary image\n",
        "        thresh = cv2.adaptiveThreshold(rotated, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "        # Find contours of all shapes\n",
        "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Filter contours to get only rectangles with at least 4 corners\n",
        "        rects = []\n",
        "        for cnt in contours:\n",
        "            approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
        "            if len(approx) == 4:\n",
        "                rects.append(approx)\n",
        "\n",
        "        # Count the number of dotted rectangles\n",
        "        num_rects = 0\n",
        "        for rect in rects:\n",
        "            x, y, w, h = cv2.boundingRect(rect)\n",
        "            roi = thresh[y:y+h, x:x+w]\n",
        "            contours, _ = cv2.findContours(roi, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            for cnt in contours:\n",
        "                if cv2.contourArea(cnt) < 10:\n",
        "                    continue\n",
        "                rect = cv2.minAreaRect(cnt)\n",
        "                if rect[1][0] > 50 and rect[1][1] > 2:\n",
        "                    num_rects += 1\n",
        "\n",
        "    # Rotate the original image by the found angle and return it\n",
        "    rotated = imutils.rotate_bound(img, angle)\n",
        "    return rotated\n",
        "\n",
        "import cv2\n",
        "\n",
        "def crop_to_mini_rectangles(img):\n",
        "    # Read the image and convert to grayscale\n",
        "    # img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding to get a binary image\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    # Find contours of all shapes\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter contours to get only rectangles with at least 4 corners\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
        "        if len(approx) == 4:\n",
        "            rects.append(approx)\n",
        "\n",
        "    # Find the minimum and maximum x and y coordinates of all rectangles\n",
        "    x_min = y_min = float('inf')\n",
        "    x_max = y_max = float('-inf')\n",
        "    for rect in rects:\n",
        "        x, y, w, h = cv2.boundingRect(rect)\n",
        "        x_min = min(x_min, x)\n",
        "        y_min = min(y_min, y)\n",
        "        x_max = max(x_max, x + w)\n",
        "        y_max = max(y_max, y + h)\n",
        "\n",
        "    # Crop the image to the area encompassed by the rectangles\n",
        "    cropped = img[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    return cropped\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_rectangles(image_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding to get a binary image\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    # Find contours of all shapes\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Filter contours to get only rectangles with at least 4 corners\n",
        "    rects = []\n",
        "    for cnt in contours:\n",
        "        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)\n",
        "        if len(approx) == 4:\n",
        "            rects.append(approx)\n",
        "\n",
        "    # Sort the rectangles from left to right and top to bottom\n",
        "    rects = sorted(rects, key=lambda x: (cv2.boundingRect(x)[1], cv2.boundingRect(x)[0]))\n",
        "\n",
        "    # Extract the contents within each rectangle and add it to the array of images\n",
        "    images = []\n",
        "    for rect in rects:\n",
        "        x, y, w, h = cv2.boundingRect(rect)\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "        images.append(roi)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "rotated = detect_tilted_rectangles(image_path)\n",
        "cropped = crop_black_borders(rotated)\n",
        "mini_rect = extract_rectangles(image_path)\n",
        "\n",
        "\n",
        "# gray = make_nonwhite_black(cropped)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18,6),facecolor=(1,1,1))\n",
        "plt.suptitle('index: '+str(index)+'\\n'+image_path.split('/')[-1]+'\\nlabel: '+str(label))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(cv2.cvtColor(rotated,cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(cv2.cvtColor(cropped,cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cv2.cvtColor(mini_rect,cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "Js7Kp437nwaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_images(images, nrows, ncols):\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            ax.imshow(cv2.cvtColor(images[i],cv2.COLOR_BGR2RGB))\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming images is a list of 47 images\n",
        "show_images(mini_rect, nrows=6, ncols=8)\n"
      ],
      "metadata": {
        "id": "045eoNP77H0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image[y:y+h,x:x+w])"
      ],
      "metadata": {
        "id": "r46rAjcNwG8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "cvgC8KZsvRWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, (image_files, label) in image_files.items():\n",
        "  print(index,loc,label)"
      ],
      "metadata": {
        "id": "h22Ad01fjVOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############SPLTTING OF THE TRAIN AND TEST FILES FOR KFOLD \n",
        "# from sklearn.model_selection import KFold\n",
        "# kf = KFold(n_splits=5)\n",
        "# for kfold_train, kfold_test in kf.split(train_files):\n",
        "#   # print('Train')\n",
        "#   c+=1\n",
        "#   actual_train_files = [train_files[x] for x in kfold_train]\n",
        "#   # print(actual_train_files)\n",
        "#   # print('length:',len(kfold_train))\n",
        "#   # print('Test')\n",
        "#   actual_test_files = [train_files[x] for x in kfold_test]\n",
        "#   kfold_database['FOLD_'+str(c)]={'kfold_train':str(list(kfold_train)).strip('[]'),\n",
        "#                                   'kfold_test':str(list(kfold_test)).strip('[]'),\n",
        "#                                   'NUMBER OF TRAIN FILES':len(actual_train_files),\n",
        "#                                  'TRAIN FILES':actual_train_files,\n",
        "                                  \n",
        "#                                  'NUMBER OF TEST FILES': len(actual_test_files),\n",
        "#                                  'TEST FILES':actual_test_files}\n",
        "\n",
        "#   # print(actual_test_files)\n",
        "#   # print('length:',len(kfold_test))\n",
        "\n",
        "# to_json(kfold_database,'kfold_database','write')\n",
        "  # print('------------------------------------------------------')"
      ],
      "metadata": {
        "id": "5g0l-fsPshQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ3r5egoyBTp"
      },
      "outputs": [],
      "source": [
        "# #STARTING POINT,  \n",
        "# #RUN THIS CELL TO LOAD ALL THE DATA IN THE MEMORY FOR FASTER TRAINING\n",
        "# #YOU WILL GET RUNTIMEERROR THE FIRST TIME, JUST RE-RUN THIS CELL\n",
        "# #AND AFTER THE DATA IS LOADED ONTO THE MEMORY RUN THE NEXT CELL TO TRAIN THE MODEL\n",
        "\n",
        "# from monai.networks.nets import UNet\n",
        "# import sys\n",
        "\n",
        "# from monai.networks.layers import Norm\n",
        "# from monai.losses import DiceLoss, DiceCELoss\n",
        "# import torch\n",
        "\n",
        "# #########################NOTEBOOKS IN PARALLEL OPERATION#############ONLY CHANGE THESE VARIABLES CLONE NUMBER FROM 1 TO 5, AND DESIRED EPOCHS\n",
        "# CLONE_NUMBER = 1\n",
        "# epochs = 100\n",
        "# ########################################################\n",
        "\n",
        "\n",
        "# model_dir = kfold+'DATA_FOLD_'+str(CLONE_NUMBER)+'/'\n",
        "\n",
        "# print(model_dir)\n",
        "\n",
        "# size = 128\n",
        "# data_caches_for_different_kfold_splits = []\n",
        "\n",
        "# train_files = sorted(glob(os.path.join(data_dir,\"TrainVolumes\",\"*.nii.gz\")))\n",
        "# # train_files = sorted(os.listdir(data_dir+'TrainVolumes'))\n",
        "# train_files_segmentation = sorted(glob(os.path.join(data_dir,\"TrainSegmentation\",\"*.nii.gz\")))\n",
        "\n",
        "# kfold_database = to_json({},'kfold_database','read')['FOLD_'+str(CLONE_NUMBER)]\n",
        "\n",
        "# kfold_train = [int(x) for x in kfold_database['kfold_train'].split(', ')]\n",
        "\n",
        "# kfold_test = [int(x) for x in kfold_database['kfold_test'].split(', ')]\n",
        "\n",
        "# if os.path.exists(model_dir+'graphs/') is False:\n",
        "#   os.mkdir(model_dir+'graphs/')\n",
        "\n",
        "# try:\n",
        "#   epoch_done = len(np.load(model_dir+'loss_train.npy'))\n",
        "# except Exception as e:\n",
        "#   epoch_done = 0\n",
        "\n",
        "\n",
        "# try:\n",
        "#   print(data_in)\n",
        "  \n",
        "# except NameError:\n",
        "    \n",
        "  \n",
        "#   if epochs-epoch_done >0:\n",
        "#     data_in = prepare(data_dir, kfold_train, kfold_test,cache=True,spatial_size=[size,size,64])  #### THIS ONE TAKES DATA IN THE CACHE, TO MAKE THE TRAINING FAST\n",
        "#     clone_k = CLONE_NUMBER\n",
        "\n",
        "# if clone_k != CLONE_NUMBER and epochs-epoch_done>0:\n",
        "#   data_in = prepare(data_dir, kfold_train, kfold_test,cache=True,spatial_size=[size,size,64])  #### THIS ONE TAKES DATA IN THE CACHE, TO MAKE THE TRAINING FAST\n",
        "#   clone_k = CLONE_NUMBER\n",
        "\n",
        "# print(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5IGwKRYECnM"
      },
      "outputs": [],
      "source": [
        "# #ACTUAL TRAINER, DOESNT MATTER IF TRAINING GETS INTERRUPTED, IT WILL DO THE TRAIN FROM THE\n",
        "# #NEXT EPOCH, AS LONG AS NOTHING IS TOUCHED HERE\n",
        "# device = torch.device(my_device)\n",
        "# learn_rate =  1e-5\n",
        "\n",
        "# model = UNet(\n",
        "#     spatial_dims=3,\n",
        "#     in_channels=1,\n",
        "#     out_channels=2,\n",
        "#     channels=(16, 32, 64, 128, 256),\n",
        "#     strides=(2, 2, 2, 2),\n",
        "#     num_res_units=2,\n",
        "#     norm=Norm.BATCH,\n",
        "# ).to(device)\n",
        "# go = ''\n",
        "# if os.path.exists(model_dir+'best_metric_model.pth'):\n",
        "#   print('RESUMING FROM MODEL'+sep+model_dir.split('/')[-2])\n",
        "#   model.load_state_dict(torch.load(\n",
        "#         os.path.join(model_dir, \"best_metric_model.pth\"),map_location=torch.device(my_device)))#### to resume for a specific model\n",
        "  \n",
        "#   print(epoch_done,'epochs done.......')\n",
        "#   if epochs-epoch_done > 0:\n",
        "#     print('Remaining epochs',epochs-epoch_done)\n",
        "    \n",
        "#     # model.eval()\n",
        "#     go='1'\n",
        "# else:\n",
        "#   go = '1'\n",
        "#   epoch_done = 0\n",
        "  \n",
        "# # loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(3.32088658e+08, 2.54757580e+07).to(device))\n",
        "# loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
        "\n",
        "# if go not in empty_list:\n",
        "#   print('STARTING TRAINING IN 5 SECONDS....')\n",
        "#   time.sleep(5)\n",
        "#   train(model, data_in, loss_function, optimizer, epochs-epoch_done, model_dir)\n",
        "# # except ZeroDivisionError:\n",
        "# #   clear()\n",
        "# #   train(model, data_in, loss_function, optimizer, 600, model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ####DELETE (FAULTY) EPOCH INDEX \n",
        "# CL_NUMBER = 5\n",
        "# fault_in_the_last = 0\n",
        "# delete = 0 ################################### MAKE SURE THIS IS ALWAYS 0\n",
        "\n",
        "\n",
        "# model_dir = kfold+'/DATA_FOLD_'+str(CL_NUMBER)+'/'\n",
        "\n",
        "# if delete == 85695436:\n",
        "#   delete_confirm = 1\n",
        "#   files = ['loss_train','metric_train','loss_test','metric_test']\n",
        "# else:\n",
        "#   files = ['loss_train']\n",
        "#   delete_confirm = ''\n",
        "\n",
        "\n",
        "# for f in files:\n",
        "#   if fault_in_the_last == 0:\n",
        "    \n",
        "#     a = np.load(model_dir+f+'.npy')\n",
        "#   else:\n",
        "#     a = np.load(model_dir+f+'.npy')[0:-fault_in_the_last]\n",
        "  \n",
        "\n",
        "#   if delete_confirm == 1:\n",
        "#     print('reforming',model_dir+f+'.npy')\n",
        "#     np.save(model_dir+f+'.npy',arr=a)\n",
        "    \n",
        "  \n",
        "#   print(a,'\\n')\n",
        "\n",
        "#   print(len(a))\n",
        "#   print('-------------------')\n",
        "\n"
      ],
      "metadata": {
        "id": "k2xTsMzcuvRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################## HIGHLIGHTING VALUES OF INTEREST FROM THE KFOLDED MODELS\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# models = [kfold+item+'/' for item in os.listdir(kfold)]\n",
        "\n",
        "# data_points = ['loss_train','metric_train','loss_test','metric_test']\n",
        "\n",
        "# c=0\n",
        "# kfold_findings = to_json({},'kfold_findings','read')\n",
        "# for model in models:\n",
        "#   for item in data_points:\n",
        "#     a = np.load(model+item+'.npy') \n",
        "#     e = len(a)\n",
        "#     maxa, enda, mina, starta,mean,median = max(a),a[-1],min(a),a[0],np.mean(a),np.median(a)\n",
        "#     if model.split('/')[-2] not in kfold_findings:\n",
        "#       kfold_findings[model.split('/')[-2]]={}\n",
        "    \n",
        "#     kfold_findings[model.split('/')[-2]][item]={'max':maxa,\n",
        "#                                                     'min':mina,\n",
        "#                                                     'start':starta,\n",
        "#                                                     'end':enda,\n",
        "#                                                     'mean':mean,\n",
        "#                                                     'median':median,\n",
        "#                                                     'epochs':e}\n",
        "\n",
        "# to_json(kfold_findings,'kfold_findings','write')\n",
        "\n"
      ],
      "metadata": {
        "id": "_xCI-Zq3_9Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ######################## to make KFOLDED GRAPHS\n",
        "# plt = ''\n",
        "# ax = ''\n",
        "# from matplotlib import pyplot as plt\n",
        "# from matplotlib.ticker import FormatStrFormatter\n",
        "\n",
        "# kfold_findings = to_json({},'kfold_findings','read')\n",
        "# models = ['Model '+str(i+1) for i in range(len(kfold_findings))]\n",
        "# max_val = ['metric_train','metric_test']\n",
        "# min_val = ['loss_train','loss_test']\n",
        "\n",
        "# COLOR = [0.149,0.149,0.149]\n",
        "# plt.rc('font',family='serif',size=20)\n",
        "# plt.rc('lines',linewidth=1.6)\n",
        "# plt.rcParams['axes.labelcolor'] = COLOR\n",
        "# plt.rcParams['xtick.labelsize'] = 16\n",
        "# plt.rcParams['ytick.labelsize'] = 16\n",
        "\n",
        "# plt.rcParams['xtick.color'] = COLOR\n",
        "# plt.rcParams['ytick.color'] = COLOR\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,8),facecolor=[1,1,1])\n",
        "# ax.set_facecolor([1,1,1])\n",
        "# ax.grid(visible=True,linewidth=0.20)\n",
        "\n",
        "# ax.spines['top'].set_visible(False)\n",
        "# ax.spines['right'].set_visible(False)\n",
        "# ax.spines['bottom'].set_color(COLOR)\n",
        "# ax.spines['bottom'].set_linewidth(1.6)\n",
        "# ax.spines['left'].set_linewidth(1.6)\n",
        "\n",
        "# x = []\n",
        "# y = []\n",
        "# c = 0\n",
        "# for model in kfold_findings:\n",
        "#   for item in max_val:###############################################################\n",
        "#     if item.split('_')[0] == 'loss':\n",
        "#       x.append(kfold_findings[model][item]['min'])\n",
        "#     else:\n",
        "#       x.append(kfold_findings[model][item]['max'])\n",
        "#     y.append(c+1)\n",
        "#   c+=1\n",
        "# suf = item.split('_')[0].capitalize()\n",
        "\n",
        "# if suf == 'Loss':\n",
        "#   ax.set_ylim(0,.5)\n",
        "# else:\n",
        "#   suf = 'Score'\n",
        "#   ax.set_ylim(.50,1)\n",
        "\n",
        "\n",
        "# ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
        "\n",
        "# avg1,avg2 = ' [Average: '+str(round(np.mean(x[0::2]),2))+\"]\",' [Average: '+str(round(np.mean(x[1::2]),2))+\"]\"\n",
        "# if suf != 'Loss':\n",
        "    \n",
        "#   COLOR = [255/255,10/255,10/255] ################ RED\n",
        "#   ax.plot(models,x[0::2],'--x',linewidth=2.5,color = COLOR,label='Train Dice '+suf+avg1,markersize=16)\n",
        "#   plt.bar(models,x[0::2],color=[255/255,200/255,200/255])\n",
        "\n",
        "#   COLOR = [100/255,100/255,255/255]\n",
        "#   ax.plot(models,x[1::2],'--o',linewidth=2.5,color = COLOR,label='Test Dice '+suf+avg2,markersize=8)\n",
        "#   plt.bar(models,x[1::2],color=[200/255,200/255,255/255])\n",
        "\n",
        "\n",
        "\n",
        "# else:\n",
        "\n",
        "#   COLOR = [100/255,100/255,255/255]\n",
        "#   ax.plot(models,x[1::2],'--o',linewidth=2.5,color = COLOR,label='Test Dice '+suf+avg2,markersize=8)\n",
        "#   plt.bar(models,x[1::2],color=[200/255,200/255,255/255])\n",
        "\n",
        "  \n",
        "#   COLOR = [255/255,10/255,10/255] ################ RED\n",
        "#   ax.plot(models,x[0::2],'--x',linewidth=2.5,color = COLOR,label='Train Dice '+suf+avg1,markersize=16)\n",
        "#   plt.bar(models,x[0::2],color=[255/255,200/255,200/255])\n",
        "\n",
        "  \n",
        "  \n",
        "# if suf != \"Loss\":\n",
        "#   plt.ylabel('Dice Score\\n')\n",
        "# else:\n",
        "#   plt.ylabel(\"Dice Loss\\n\")\n",
        "# plt.xlabel('\\nK-Folds')\n",
        "# plt.legend(loc = 'upper right', frameon =False,bbox_to_anchor = (1.1,1.2))\n",
        "\n",
        "\n",
        "# fig.savefig(main_path+'PAPER DATA/'+'KFOLD GRAPH'+sep+timenow()+'.png',bbox_inches='tight',facecolor=[1,1,1],dpi=600)"
      ],
      "metadata": {
        "id": "69Mmt7KHD8Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hxTLsirvcI1"
      },
      "outputs": [],
      "source": [
        "##############JUST PLOTTING\n",
        "import numpy as np, nibabel\n",
        "from matplotlib import pyplot as plt\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    AddChanneld,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "from monai.utils import first\n",
        "\n",
        "main_path = '/content/drive/MyDrive/thesis_dataset/'\n",
        "livpath = main_path+'Liver/Task03_Liver/'\n",
        "mypath = main_path+'test_path/'\n",
        "trpath = main_path+'imagesTr_path'\n",
        "labels = main_path+'labels_path'\n",
        "tspath = main_path+'imagesTs_path'\n",
        "folder = 'imagesTr'\n",
        "sixtyfournifties = main_path+'groups_of_64_nifti/'+folder+'/'\n",
        "\n",
        "\n",
        "\n",
        "inc = 0\n",
        "\n",
        "for jk in range(0,1):\n",
        "\n",
        "  file_num = np.random.randint(0,130)\n",
        "  slice_number1 = np.random.randint(0,64)\n",
        "\n",
        "  while True:\n",
        "    try:\n",
        "      sub_file = np.random.randint(0,10)\n",
        "      file_name1 = sixtyfournifties+'liver_'+str(file_num)+'_'+str(sub_file)+'.nii.gz'\n",
        "      file_name2 = livpath+'labelsTr/'+'liver_'+file_name1.split('.nii.gz')[0].split('_')[-2]+'.nii.gz'\n",
        "      file_name3 = livpath+'imagesTr/'+'liver_'+file_name1.split('.nii.gz')[0].split('_')[-2]+'.nii.gz'\n",
        "      slice_number = int(file_name1.split('.nii.gz')[0].split('_')[-1])*64+slice_number1\n",
        "  # plt.rcParams['text.color'] = [1,1,1]\n",
        "\n",
        "      files = os.listdir(sixtyfournifties)\n",
        "      test_image1 = nibabel.load(file_name1).get_fdata()\n",
        "      test_image2 = nibabel.load(file_name2).get_fdata()==1\n",
        "      test_image3 = nibabel.load(file_name3).get_fdata()\n",
        "    except:\n",
        "      continue\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  ##################TO MAKE IT HOW IT LOOKS IN THE 3D SLICER\n",
        "  test_image1 = correct_orient(test_image1)\n",
        "  test_image2 = correct_orient(test_image2)\n",
        "  test_image3 = correct_orient(test_image3)\n",
        "  # test_image1 = np.fliplr(test_image1)\n",
        "  # test_image1 = np.rot90(test_image1,3)\n",
        "  # test_image2 = np.fliplr(test_image2)\n",
        "  # test_image2 = np.rot90(test_image2,3)\n",
        "  # test_image3 = np.fliplr(test_image3)\n",
        "  # test_image3 = np.rot90(test_image3,3)\n",
        "  #####################################################\n",
        "  plt = ''\n",
        "  ax = ''\n",
        "  from matplotlib import pyplot as plt\n",
        "  \n",
        "  fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,5))\n",
        "  plt.rc('font',family='serif',size=20)\n",
        "  # plt.axis('off')\n",
        "  COLOR = [1,1,1]\n",
        "  plt.rcParams['axes.labelcolor'] = COLOR\n",
        "  plt.rcParams['xtick.color'] = COLOR\n",
        "  plt.rcParams['ytick.color'] = COLOR\n",
        "  \n",
        "  \n",
        "  try:\n",
        "    ax1.imshow(test_image1[:,:,slice_number1],cmap='gray')\n",
        "    # ax1.set_title('SLICED\\n'+file_name1.split('/')[-1])\n",
        "    # ax1.set_title('SLICED ['+str(slice_number1)+'/'+str(test_image1.shape[-1]-1)+']\\n'+file_name1.split('/')[-1])\n",
        "    ax1.set_title('64 Sliced NIfTI\\nImage')\n",
        "  except IndexError:\n",
        "    ax1.set_title('out of bounds')\n",
        "  # ax2.set_title('ORIGINAL IMAGE ['+str(slice_number)+'/'+str(test_image3.shape[-1]-1)+']\\n'+file_name3.split(livpath)[-1])\n",
        "  ax2.set_title('64 Sliced NIfTI\\nImage Segmentation')\n",
        "  # plt.suptitle('Slice number '+str(slice_number))\n",
        "  ax2.imshow(test_image2[:,:,slice_number],cmap='gray')\n",
        "  # ax3.set_title('ORIGINAL LABEL ['+str(slice_number)+'/'+str(test_image2.shape[-1]-1)+']\\n'+file_name2.split(livpath)[-1])\n",
        "  # plt.suptitle('Slice number '+str(slice_number))\n",
        "  # ax3.imshow(test_image2[:,:,slice_number],cmap='gray')\n",
        "  plt.savefig(main_path+'TESTED_DATA/SLICING '+timenow()+'.png',bbox_inches='tight',dpi=600)\n",
        "  plt.show()\n",
        "  print('SAVED slice....')\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6HeJhNhTdw6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "model_dir = main_path+'model_results/with_dropout=0.5/'\n",
        "model_dir = main_path+'model_results/without_dropout/'\n",
        "# model_dir = main_path+'MODELscratch_2/'\n",
        "# model_dir = main_path+'MODEL/'\n",
        "try:\n",
        "  extra = ''\n",
        "  train_loss = np.load(os.path.join(model_dir, extra+ 'loss_train.npy'))\n",
        "  train_metric = np.load(os.path.join(model_dir, extra+ 'metric_train.npy'))\n",
        "  test_loss = np.load(os.path.join(model_dir, extra+ 'loss_test.npy'))\n",
        "  test_metric = np.load(os.path.join(model_dir, extra+ 'metric_test.npy'))\n",
        "except Exception as e:\n",
        "  extra = 'Copy of '\n",
        "  train_loss = np.load(os.path.join(model_dir, extra+ 'loss_train.npy'))\n",
        "  train_metric = np.load(os.path.join(model_dir, extra+ 'metric_train.npy'))\n",
        "  test_loss = np.load(os.path.join(model_dir, extra+ 'loss_test.npy'))\n",
        "  test_metric = np.load(os.path.join(model_dir, extra+ 'metric_test.npy'))\n",
        "\n",
        "\n",
        "plt.rc('font',family='serif',size=20)\n",
        "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(12,6))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.plot(test_loss,range(len(test_loss)))\n",
        "\n",
        "# a, = ax[0].plot(test_loss,'o-',label='test_loss')\n",
        "# b, = ax[0].plot(train_loss,'x--',label='train_loss')\n",
        "\n",
        "# ax[0].set_title('DICE loss')\n",
        "# ax[0].legend(handles=[a,b])\n",
        "# # plt.legend()\n",
        "# ax[0].grid()\n",
        "# ax[0].set_yticks(np.linspace(min(test_loss),max(test_loss),10))\n",
        "# ax[0].set_xticks(np.linspace(0,len(test_loss),10))\n",
        "# plt.subplot(2,1,2)\n",
        "\n",
        "##############METRIC\n",
        "# suff = '_metric'\n",
        "# a, = ax.plot(test_metric,'o-',label='Test Dice Score')\n",
        "# b, = ax.plot(train_metric,'x--',label='Train Dice Score')\n",
        "\n",
        "# ################LOSS\n",
        "suff = '_loss'\n",
        "a, = ax.plot(test_loss,'o-',label='Test Dice Loss Score')\n",
        "b, = ax.plot(train_loss,'x--',label='Train Dice Loss Score')\n",
        "\n",
        "\n",
        "# plt.rcParams['text.color'] = [0,0,0]\n",
        "ax.legend(handles=[a,b])\n",
        "# ax.set_title('DICE metric')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice Loss')\n",
        "# plt.suptitle('Epoch'+sep+str(len(train_loss)),va='top',fontsize=22)\n",
        "ax.grid()\n",
        "# if os.path.exists(model_dir+'graphs/') is False:\n",
        "#   os.mkdir(model_dir+'graphs/')\n",
        "# plt.legend()\n",
        "file_name = model_dir.split('/')[-2]+suff+'.png'\n",
        "print('MODEL NAME:','_'.join(file_name.split('_')[0:2])+'\\n')\n",
        "print('Data points:',len(train_metric),'\\n')\n",
        "print('-------------METRICS----------------')\n",
        "print('MAX TRAIN METRIC:',round(max(train_metric),3),', MAX TEST METRIC:',round(max(test_metric),3))\n",
        "print('MIN TRAIN METRIC:',round(min(train_metric),3),', MIN TEST METRIC:',round(min(test_metric),3))\n",
        "print('LAST TRAIN METRIC:',round((train_metric)[-1],3),', LAST TEST METRIC:',round((test_metric)[-1],3))\n",
        "\n",
        "print('\\n-------------LOSS METRICS----------------')\n",
        "print('MAX TRAIN LOSS METRIC:',round(max(train_loss),3),', MAX TEST LOSS METRIC:',round(max(test_loss),3))\n",
        "print('MIN TRAIN LOSS METRIC:',round(min(train_loss),3),', MIN TEST LOSS METRIC:',round(min(test_loss),3))\n",
        "print('LAST TRAIN METRIC:',round((train_loss)[-1],3),', LAST TEST METRIC:',round((test_loss)[-1],3))\n",
        "print('\\n\\n\\n\\n')\n",
        "print(file_name)\n",
        "plt.savefig(main_path+'TESTED_DATA/'+file_name,bbox_inches='tight',dpi=600)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wc3ZXbpRgKD"
      },
      "outputs": [],
      "source": [
        "#this is the starting cell, ENTER CTRL+F8, TO RUN THE CELLS ABOVE\n",
        "# to test random slices and getting predictions\n",
        "# index = 331 \n",
        "in_dir = traindir\n",
        "for i in range(0,10):\n",
        "  # clear()\n",
        "  try:\n",
        "    index = np.random.randint(0,366)\n",
        "\n",
        "    slice_number1 = np.random.randint(0,64)\n",
        "    # print(index,file_index,slice_number1)\n",
        "\n",
        "\n",
        "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))[index:]\n",
        "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))[index:]\n",
        "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
        "    \n",
        "    ###########################################################################################\n",
        "    file_index = np.random.randint(0,len(test_files)-1)\n",
        "    start_slice, threshold_of_error = np.random.randint(0,64),np.random.randint(53,85)\n",
        "    ############################################################################################\n",
        "\n",
        "\n",
        "    test_files = test_files[file_index-1:file_index]\n",
        "    file_name1 = test_files[0]['vol']\n",
        "    \n",
        "    \n",
        "    end_slice = start_slice\n",
        "    colormap = 'gray' #Grey, gray\n",
        "    \n",
        "    ################models\n",
        "    # model_path = main_path+'/MODELscratch_2/best_metric_model.pth'\n",
        "    model_path = main_path+'/model_results/without_dropout/best_metric_model.pth'\n",
        "    # model_path = main_path+'/model_results/with_dropout=0.5/best_metric_model.pth'\n",
        "    # model_path = main_path+'/MODELscratch/best_metric_model.pth'\n",
        "    # model_path = ''        ###TO SEE WHAT HAPPENS WHEN NO MODEL IS USED\n",
        "\n",
        "    # model_path = main_path+'/MODELscratch_2/best_metric_model.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model_00.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model_nogood.pth'\n",
        "    \n",
        "\n",
        "    ####################################\n",
        "\n",
        "\n",
        "    predicting_liver_mask_for_new_files(file_index,\n",
        "                                        start_slice,end_slice,\n",
        "                                        colormap,\n",
        "                                        threshold_of_error/100,\n",
        "                                        model_path=model_path)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    # clear()\n",
        "  # continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MYdtwduF8drN"
      },
      "outputs": [],
      "source": [
        "# to test random slices and getting predictions TEST SLICES\n",
        "# index = 331 \n",
        "in_dir = traindir\n",
        "for i in range(0,10):\n",
        "  # clear()\n",
        "  try:\n",
        "    # index = np.random.randint(0,366)\n",
        "\n",
        "    \n",
        "    # print(index,file_index,slice_number1)\n",
        "\n",
        "\n",
        "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
        "    test_files = [{\"vol\": image_name} for image_name in path_test_volumes]\n",
        "    \n",
        "    ###############################################################\n",
        "    file_index = np.random.randint(0,len(test_files)-1)\n",
        "    start_slice = np.random.randint(0,64)\n",
        "    ###############################################################\n",
        "\n",
        "    test_files = test_files[file_index-1:file_index]\n",
        "    file_name1 = test_files[0]['vol']\n",
        "    # print('file_name',file_name1)\n",
        "    \n",
        "    end_slice = start_slice\n",
        "    colormap = 'gray' #Grey, gray\n",
        "    \n",
        "    ################models\n",
        "    model_path = main_path+'/MODELscratch_2/best_metric_model.pth'\n",
        "    model_path = main_path+'/MODELscratch/best_metric_model.pth'\n",
        "    # model_path = ''        ###TO SEE WHAT HAPPENS WHEN NO MODEL IS USED\n",
        "\n",
        "    # model_path = main_path+'/MODELscratch_2/best_metric_model.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model_00.pth'\n",
        "    # model_path = main_path+'/MODEL/best_metric_model_nogood.pth'\n",
        "    model_path = main_path+'/model_results/without_dropout/best_metric_model.pth'\n",
        "\n",
        "    ####################################\n",
        "    predicting_liver_mask_for_test_files_without_segmentation(test_files,\n",
        "                                        start_slice,end_slice,\n",
        "                                        colormap,\n",
        "                                        model_path=model_path)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    # clear()\n",
        "  # continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiNIkdzbzOym"
      },
      "outputs": [],
      "source": [
        "#selfexplanatory\n",
        "for i in range(10):\n",
        "  shows_processed_image_pipeline_for_a_random_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWkGn4A3wfrd"
      },
      "outputs": [],
      "source": [
        "###MAKES PDF \n",
        "from PIL import Image\n",
        "pdpath = main_path+'PAPER DATA/'\n",
        "\n",
        "if os.path.exists(pdpath+'/PDF/') is not True:\n",
        "  print('making pdf folder')\n",
        "  os.mkdir(pdpath+'/PDF/')\n",
        "\n",
        "for item in os.listdir(pdpath):\n",
        "  image_file = pdpath+item\n",
        "  \n",
        "  \n",
        "  try:\n",
        "    pdf_file_name = pdpath+'/PDF/'+os.path.splitext(item)[0]+'.pdf'\n",
        "    if os.path.exists(pdf_file_name):\n",
        "      getfilesize(pdf_file_name,'')\n",
        "      continue\n",
        "    else:\n",
        "      im = Image.open(image_file).convert('RGB')\n",
        "      im.save(pdf_file_name,dpi=(600,600))\n",
        "      getfilesize(pdf_file_name,'')\n",
        "    \n",
        "  except IsADirectoryError:\n",
        "    continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZORU8fkySyK"
      },
      "outputs": [],
      "source": [
        "# for files in os.listdir(pdpath):\n",
        "#   # im = Image.open(pdpath+files)\n",
        "#   # print(files,sep,im.info['dpi'])\n",
        "#   try:\n",
        "#     os.remove(pdpath+files)\n",
        "#   except IsADirectoryError:\n",
        "#     continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9a0ohUtCSB2"
      },
      "outputs": [],
      "source": [
        "################DICOM TO NIFTY CONVERTER USING SITK\n",
        "# # labels = 74\n",
        "# # trpath = 74\n",
        "# # tspath = 42\n",
        "\n",
        "\n",
        "\n",
        "# group_folder = 'labelsTr'\n",
        "\n",
        "# copy_path = main_path+'groups_of_64/'+group_folder+'/'\n",
        "# paste_path = main_path+'groups_of_64_nifti/'+group_folder+'/'\n",
        "\n",
        "# file_name = 'liver_1_0'\n",
        "# count = 0\n",
        "# upto = len(os.listdir(copy_path))\n",
        "# clone = 0\n",
        "# a,b = (clone*int(np.ceil(upto/5)),(clone+1)*int(np.ceil(upto/5)))\n",
        "# # os.listdir(copy_path)[a:b]\n",
        "# upto = int(np.ceil(upto/5))\n",
        "# # for file_name in (os.listdir(copy_path))[a:b]:\n",
        "\n",
        "# mult = int(file_name.split('_')[-1])\n",
        "# print('('+str(count+1)+'/'+str(upto)+')')\n",
        "# if os.path.exists(paste_path+file_name+'nii.gz') is not True:\n",
        "#   # break\n",
        "#   # clear()\n",
        "#   print('\\nConverting',file_name)\n",
        "#   print('dicom_series:',copy_path+file_name)\n",
        "#   print('nifti_file:',paste_path+file_name+'.nii.gz')\n",
        "  \n",
        "#   # clear()\n",
        "#   reader = sitk.ImageSeriesReader()\n",
        "#   dicom_names = sequential_series(mult,copy_path+file_name)\n",
        "#   reader.SetFileNames(dicom_names)\n",
        "#   image = reader.Execute()\n",
        "#   image = sitk.Flip(image,[True,False,False])\n",
        "#   image = sitk.Flip(image,[False,True,False])\n",
        "\n",
        "\n",
        "#   sitk.WriteImage(image, paste_path+file_name+'.nii.gz')\n",
        "#   print('Conversion done')\n",
        "#   clear()\n",
        "# else:\n",
        "#   j = sequential_series(mult,copy_path+file_name)\n",
        "#   print(file_name,'already exists')\n",
        "#   clear()\n",
        "\n",
        "# count+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AnOVw3iEwgn"
      },
      "outputs": [],
      "source": [
        "#####NON EMPTY SEPARATOR\n",
        "# group_folder = 'labelsTr'\n",
        "# print('DOING',group_folder)\n",
        "# g64n = main_path+'groups_of_64_nifti/'+group_folder+'/'\n",
        "# g64ne = main_path+'groups_of_64_nifti_non_empty/'+group_folder+'/'\n",
        "# number_of_files = len(os.listdir(g64n)),len(os.listdir(g64))\n",
        "\n",
        "# upto = len(os.listdir(g64n))\n",
        "# clone = 0\n",
        "# a,b = (clone*int(np.ceil(upto/5)),(clone+1)*int(np.ceil(upto/5)))\n",
        "\n",
        "# for files in tqdm(os.listdir(g64n)[a:b]):\n",
        "#   # getfilesize(g64n+files,'')\n",
        "#   f = nibabel.load(g64n+files).get_fdata()\n",
        "#   if len(np.unique(f)) == 1:\n",
        "#     print('\\n',files)\n",
        "#   else:\n",
        "#     shutil.copy(g64n+files,g64ne+files)\n",
        "#     shutil.copy(main_path+'groups_of_64_nifti/imagesTr/'+files,main_path+'groups_of_64_nifti_non_empty/imagesTr/'+files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ynn63RSQdGF"
      },
      "outputs": [],
      "source": [
        "#GETTING THE 64 SLICES DIRECTLY FROM NIFTY\n",
        "# group_folder = 'imagesTr'\n",
        "\n",
        "# og_path = livpath+group_folder+'/'\n",
        "# upto = len(os.listdir(og_path))\n",
        "# clone = 1\n",
        "# c,d = (clone*int(np.ceil(upto/5)),(clone+1)*int(np.ceil(upto/5)))\n",
        "# ext = '.nii.gz'\n",
        "# count = 0\n",
        "\n",
        "# # the_file_name = 'liver_0.nii.gz'\n",
        "\n",
        "# for the_file_name in os.listdir(og_path)[c:d]:\n",
        "#   if the_file_name.startswith('.') is not True:\n",
        "#     copy_path = og_path+the_file_name\n",
        "#     paste_path = main_path+'groups_of_64_nifti/'+group_folder+'/'+the_file_name.split(ext)[0]\n",
        "\n",
        "#     original_nifty_file = load(copy_path)\n",
        "#     number_of_slices = original_nifty_file.shape[-1]\n",
        "#     clear()\n",
        "\n",
        "#     tick = int(number_of_slices/64)\n",
        "#     clear()\n",
        "#     print('('+str(count+1)+'/'+str(upto)+')')\n",
        "#     print('Converting',the_file_name)\n",
        "#     print('partition number:',tick)\n",
        "#     for i in range(tick):\n",
        "#       if os.path.exists(paste_path+'_'+str(i)+ext) is not True:\n",
        "#         a,b = i*64,(i+1)*64\n",
        "#         roi  = np.asarray(original_nifty_file.dataobj[:,:,slice(a,b)])\n",
        "#         img = Nifti1Image(roi,affine=original_nifty_file.affine)\n",
        "#         # save()\n",
        "#         print('\\nSlice',a,'to',b,'from',copy_path.split(livpath)[-1])\n",
        "#         print('Saving to',the_file_name.split(ext)[0]+'_'+str(i)+ext)\n",
        "#         save(img,paste_path+'_'+str(i)+ext)\n",
        "#       else:\n",
        "#         clear()\n",
        "#         print(the_file_name.split(ext)[0]+'_'+str(i)+ext,'is already saved.')\n",
        "\n",
        "#     count+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MhQi2K0inXF"
      },
      "outputs": [],
      "source": [
        "# print(traindir)\n",
        "# for item in os.listdir(traindir):\n",
        "#   print(item,sep,format_size(get_dir_size(traindir+item)))\n",
        "#   print('number of items',sep,len(os.listdir(traindir+item)),'\\n')\n",
        "\n",
        "# print('\\n',main_path+'groups_of_64_nifti_non_empty/')\n",
        "# for item in os.listdir(main_path+'groups_of_64_nifti_non_empty/'):\n",
        "  \n",
        "#   print(item,sep,format_size(get_dir_size(main_path+'groups_of_64_nifti_non_empty/'+item)))\n",
        "#   print('number of items',sep,len(os.listdir(main_path+'groups_of_64_nifti_non_empty/'+item)),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsBNbMxEoIt8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDBMYG8PnuNQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for files in os.listdir(main_path+'groups_of_64/imagesTs'):\n",
        "#   try:\n",
        "#     file_size = format_size(get_dir_size(main_path+'groups_of_64/imagesTs/'+files))\n",
        "#     if file_size != '33.63 MB':\n",
        "#       print(files,sep,file_size)\n",
        "\n",
        "#   except NotADirectoryError:\n",
        "#     continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhZf23C0ZZ_t"
      },
      "outputs": [],
      "source": [
        "##nifty to dicom slices\n",
        "# nifty_folder = 'imagesTs'\n",
        "# dcom_path = tspath\n",
        "# the_file_name = 'liver_187.nii.gz'\n",
        "# # for the_file_name in os.listdir(livpath+nifty_folder):\n",
        "# if the_file_name.startswith('.') is not True:\n",
        "#   clear()\n",
        "#   print('checking',the_file_name,'\\n')\n",
        "#   nifty_file = livpath+nifty_folder+'/'+the_file_name\n",
        "#   nifti_file = nibabel.load(nifty_file)\n",
        "#   nifti_array = nifti_file.get_fdata()\n",
        "#   number_slices = nifti_array.shape[2]\n",
        "#   dcom_folder = dcom_path+'/'+the_file_name\n",
        "#   dcom_file_number = len(os.listdir(dcom_folder))\n",
        "\n",
        "#   # if number_slices != dcom_file_number:\n",
        "#   print(the_file_name,number_slices,sep,dcom_file_number)\n",
        "#   nifti2dicom_mfiles(nifty_file,dcom_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmW3v_ZBn2En"
      },
      "outputs": [],
      "source": [
        "# ##checking if the group_of_64_nifti has the same 64 slices or not\n",
        "# folder = 'imagesTr'\n",
        "# sixtyfournifties = livpath+folder+'/' \n",
        "# size_dict = {}\n",
        "# for item in tqdm(os.listdir(sixtyfournifties)):\n",
        "#   # print('checking',item)\n",
        "#   the_file = sixtyfournifties+item\n",
        "#   if item.startswith('.') is not True:\n",
        "    \n",
        "#     the_file = nibabel.load(the_file)\n",
        "#     nifti_array = the_file.get_fdata()\n",
        "#     number_slices = nifti_array.shape[2]\n",
        "#     if number_slices not in size_dict:\n",
        "#       size_dict[number_slices]=[item]\n",
        "#     else:\n",
        "#       size_dict[number_slices].append(item)\n",
        "#   # if number_slices != 64:\n",
        "#   #   clear()\n",
        "#   #   print('this one has less',item)\n",
        "#   #   break\n",
        "\n",
        "#   # else:\n",
        "#   #   clear()\n",
        "#   #   print('\\nsize',number_slices)\n",
        "# size_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH0QQLm9jdpA"
      },
      "outputs": [],
      "source": [
        "# t = to_json(size_dict,'slice of files','read')\n",
        "# k = []\n",
        "# for item in t.keys():\n",
        "#   k.append(int(item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW-jEtcqkbJ3"
      },
      "outputs": [],
      "source": [
        "# min(k),max(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K_GvbKnUpsU"
      },
      "outputs": [],
      "source": [
        "##slice 64 from the extracted dicoms into corresponding patient nifty\n",
        "# group_folder = 'labelsTr'+'/'\n",
        "# dcom_folder = labels+'/'\n",
        "\n",
        "# g64 = main_path+'groups_of_64/'+group_folder\n",
        "\n",
        "\n",
        "# the_file_name = 'liver_23.nii.gz'\n",
        "\n",
        "# # for the_file_name in os.listdir(dcom_folder):\n",
        "# clear()\n",
        "# number = len(os.listdir(dcom_folder+the_file_name))\n",
        "# the_name_of_the_patient = the_file_name.split('.')[0]\n",
        "# cluster = []\n",
        "# group_no = 0\n",
        "\n",
        "# possible = int(number/64)\n",
        "# print('for patient',the_name_of_the_patient,'\\ntotal_file',number,'\\npossible partitions',possible)\n",
        "\n",
        "# for i in range(number):\n",
        "#   # print(i)\n",
        "  \n",
        "#   cluster.append('slice'+str(i)+'.dcm')\n",
        "#   if len(cluster)==64:\n",
        "    \n",
        "#     slices_to_folder(the_name_of_the_patient,group_no,cluster,g64,dcom_folder)\n",
        "#     print(the_name_of_the_patient+'_'+str(group_no),sep,cluster)\n",
        "#     cluster=[]\n",
        "#     group_no+=1\n",
        "\n",
        "# if cluster != []:\n",
        "#   print('Remainder',len(cluster),sep,cluster)\n",
        "\n",
        "# cache_easy['DATA_FOLD_'+sep+str(c)]={data_in}\n",
        "\n",
        "# to_json(cache_easy,'cache_easy','write')\n",
        "\n",
        "# device = torch.device(\"cuda\")\n",
        "# model = UNet(\n",
        "#     dimensions=3,\n",
        "#     in_channels=1,\n",
        "#     out_channels=2,\n",
        "#     channels=(16, 32, 64, 128, 256), \n",
        "#     strides=(2, 2, 2, 2),\n",
        "#     num_res_units=2,\n",
        "#     norm=Norm.BATCH,\n",
        "# ).to(device)\n",
        "\n",
        "# max_epochs = 600\n",
        "# # test_interval = 1\n",
        "# # #loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\n",
        "# loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
        "# train(model, data_in, loss_function, optimizer, epochs, model_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1rl9V3k-_lvstRjwinclroWVMIqaO-NPL",
      "authorship_tag": "ABX9TyMbmp/HZsgqcrVIo9MNSb2A",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}